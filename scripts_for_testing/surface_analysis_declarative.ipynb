{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Surface Analysis \n",
    "\n",
    "Script is written so date, time, and location input can be taken from the user when run as a .py file or \n",
    "can be input before the cell is run as a .ipynb file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from metpy.calc import reduce_point_density\n",
    "import metpy.calc as mpcalc\n",
    "from metpy.plots import StationPlot, wx_code_to_numeric\n",
    "from metpy.plots.wx_symbols import sky_cover, current_weather\n",
    "from metpy.units import units\n",
    "from metpy.interpolate import interpolate_to_grid, remove_nan_observations, interpolate_to_points\n",
    "from metpy.io import metar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNIX_TIME = datetime(1970,1,1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date, time, and location\n",
    "\n",
    "Here the user can input a date, time, and coordinates for the map to be plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286.24083333333334\n"
     ]
    }
   ],
   "source": [
    "#set time to plot\n",
    "start_year  = 2023\n",
    "start_month = 3\n",
    "start_day   = 22\n",
    "start_hour  = 0\n",
    "start_min   = 0\n",
    "    \n",
    "#set plot domain\n",
    "lat_min = 33\n",
    "lat_max = 43\n",
    "lon_min = -123\n",
    "lon_max = -113\n",
    "    \n",
    "dt = datetime(start_year,start_month,start_day,start_hour,start_min)\n",
    "del_t = datetime.now()-dt\n",
    "del_t_days = del_t.days + (del_t.seconds/60/60/24)\n",
    "del_t_hours = del_t_days * 24.\n",
    "\n",
    "print(del_t_hours)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Data\n",
    "\n",
    "Data is downladed and extracted from MADIS data archived by NCEP (https://madis-data.cprk.ncep.noaa.gov/madisPublic1/data/archive/).  Note this archive has an approximately 48 hour delay.\n",
    "\n",
    "If more recent data is requested, it will be retrieved from the live MADIS filelisting (https://madis-data.cprk.ncep.noaa.gov/madisPublic1/data/point/metar/netcdf/).  To be safe and account for delays in archiving, this link is used for data within the past 100 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://madis-data.cprk.ncep.noaa.gov/madisPublic1/data/archive/2023/03/22/point/metar/netcdf/20230322_0000.gz\n"
     ]
    }
   ],
   "source": [
    "#get the data\n",
    "import requests\n",
    "import gzip\n",
    "import shutil\n",
    "\n",
    "if del_t_hours>100:\n",
    "    #download and extract the data\n",
    "    base_url = 'https://madis-data.cprk.ncep.noaa.gov/madisPublic1/data/archive/'\n",
    "    url = f'{base_url}{dt:%Y}/{dt:%m}/{dt:%d}/point/metar/netcdf/{dt:%Y%m%d_%H%M}.gz'\n",
    "\n",
    "else:\n",
    "    base_url = 'https://madis-data.cprk.ncep.noaa.gov/madisPublic1/data/point/metar/netcdf/'\n",
    "    url = f'{base_url}{dt:%Y%m%d_%H%M}.gz'\n",
    "\n",
    "print(url)\n",
    "\n",
    "r = requests.get(url,allow_redirects=True)\n",
    "open('temp.nc.gz','wb').write(r.content)\n",
    "with gzip.open('temp.nc.gz','rb') as f_in:\n",
    "    with open('temp.nc','wb') as f_out:\n",
    "        shutil.copyfileobj(f_in,f_out)\n",
    "data=Dataset('temp.nc','r')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing data\n",
    "\n",
    "The data is processed, converted to station plots, and placed into a dataframe for trimming in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17281/2315298185.py:29: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  name = [i.tostring().decode()[:4] for i in name]\n",
      "/tmp/ipykernel_17281/2315298185.py:31: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  sky_cov = [(i[0].tostring().decode()).rstrip('\\x00') for i in sky_cov]\n",
      "/tmp/ipykernel_17281/2315298185.py:45: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  wx = [(i.tostring().decode()).rstrip('\\x00') for i in wx]\n"
     ]
    }
   ],
   "source": [
    "time = [UNIX_TIME + timedelta(seconds=float(t)) for t in data['timeNominal']]\n",
    "lat = data['latitude'][:]\n",
    "lat = lat.filled(np.nan)\n",
    "lon = data['longitude'][:]\n",
    "lon = lon.filled(np.nan)\n",
    "temp = data['temperature'][:]\n",
    "temp = temp.filled(np.nan)\n",
    "temp[temp<100]=np.nan\n",
    "temp = (temp-273.15)\n",
    "dwpt = data['dewpoint'][:]\n",
    "dwpt = dwpt.filled(np.nan)\n",
    "dwpt[dwpt<100]=np.nan\n",
    "dwpt = (dwpt-273.15)\n",
    "wspd = data['windSpeed'][:]\n",
    "wspd = wspd.filled(np.nan)\n",
    "wspd[wspd>250] = np.nan\n",
    "wdir = data['windDir'][:]\n",
    "wdir = wdir.filled(np.nan)\n",
    "wdir[wdir<0] = np.nan\n",
    "gust = data['windGust'][:]\n",
    "gust = gust.filled(np.nan)\n",
    "gust[gust<0] = np.nan\n",
    "pres = data['seaLevelPress'][:]/100.0\n",
    "pres = pres.filled(np.nan)\n",
    "#pres[pres<900] = np.nan\n",
    "#pres[pres>1100] = np.nan\n",
    "#print(pres)\n",
    "name = data['stationName'][:]\n",
    "name = [i.tostring().decode()[:4] for i in name]\n",
    "sky_cov = data['skyCover'][:]\n",
    "sky_cov = [(i[0].tostring().decode()).rstrip('\\x00') for i in sky_cov]\n",
    "sky_cvr = np.zeros(len(sky_cov),dtype=int)\n",
    "clr_inds = [n for n,i in zip(range(len(sky_cov)),sky_cov) if i==\"CLR\"]\n",
    "sky_cvr[clr_inds] = 0\n",
    "few_inds = [n for n,i in zip(range(len(sky_cov)),sky_cov) if i==\"FEW\"]\n",
    "sky_cvr[few_inds] = 2\n",
    "sct_inds = [n for n,i in zip(range(len(sky_cov)),sky_cov) if i==\"SCT\"]\n",
    "sky_cvr[sct_inds] = 4\n",
    "bkn_inds = [n for n,i in zip(range(len(sky_cov)),sky_cov) if i==\"BKN\"]\n",
    "sky_cvr[bkn_inds] = 6\n",
    "ovc_inds = [n for n,i in zip(range(len(sky_cov)),sky_cov) if i==\"OVC\"]\n",
    "sky_cvr[ovc_inds] = 8\n",
    "wx = data['presWeather'][:]\n",
    "pres_wx = np.zeros(len(lat))\n",
    "wx = [(i.tostring().decode()).rstrip('\\x00') for i in wx]\n",
    "for i in range(len(wx)):\n",
    "    this_wx = wx[i].split()\n",
    "    if this_wx == []:\n",
    "        pres_wx[i] = 0\n",
    "        continue\n",
    "    pres_wx[i] = wx_code_to_numeric(this_wx)[0]\n",
    "pres_wx = pres_wx.astype(int)\n",
    "#print([wx_code_to_numeric(i) for i in wx])\n",
    "#sky_cov[sky_cov==\"CLR\"] = 0.0\n",
    "#sky_cov[sky_cov==\"FEW\"] = 0.25 \n",
    "#print(wx)\n",
    "    \n",
    "u,v = mpcalc.wind_components((wspd*units('m/s')).to('knots'),wdir*units.degree)\n",
    "\n",
    "#u = np.abs(wspd) * np.cos(np.deg2rad(270-wdir))\n",
    "#u[np.abs(u)>250] = np.nan\n",
    "#v = np.abs(wspd) * np.sin(np.deg2rad(270-wdir))\n",
    "#v[np.abs(v)>250] = np.nan\n",
    "\n",
    "#u=u*units['kts']\n",
    "#v=v*units['kts']\n",
    "\n",
    "df = pd.DataFrame(np.transpose(np.array([time,name,name,lon,lat,u,v,temp,dwpt,pres,sky_cvr,pres_wx])),\n",
    "                      columns = ['time','id','name','lon','lat','u','v','temp','dwpt','pres','sky_cvr','wx'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trimming data\n",
    "\n",
    "The data is trimmed to drop data outside of the latitude and longitude frame requested by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  drop data outside of domain\n",
      "    dropped 6754 observations\n"
     ]
    }
   ],
   "source": [
    "print('  drop data outside of domain')\n",
    "to_drop = df[(df['lat'] > lat_max+10) | (df['lat'] < lat_min-10) | (df['lon'] > lon_max+10) | (df['lon'] < lon_min-10)].index\n",
    "print('    dropped %i observations'%len(to_drop))\n",
    "df_trim = df.drop(to_drop,inplace=False)\n",
    "df_trim.set_index(['time','id'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing Surface Pressure\n",
    "There are two options to analyze surface pressure.  The first is a single pass Cressman () analysis.  The second is a multiple pass (successive corrections; ) analysis using the Cressman () weighting function.  The multiple pass, successive corrections converges to observation values at the observation locations which can be desirable, but can also converge to error.  While the single pass will only feature fine-scale or large-scale features based upon the search radius, the successive corrections will fit both fine-scale and large-scale features, but requires more computational overhead.\n",
    "\n",
    "User input:\n",
    "Set if successive corrections are used, otherwise, provide a search radius (in meters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "successive_corrections = True\n",
    "search_radius = 300000 #only used if successive_corrections is false\n",
    "\n",
    "proj = ccrs.LambertConformal(central_latitude=(lat_min+lat_max) / 2,\n",
    "                                     central_longitude=(lon_min+lon_max) / 2)\n",
    "\n",
    "slpdf = df_trim.dropna(subset=['pres'],inplace=False)\n",
    "    \n",
    "point_locs = proj.transform_points(ccrs.PlateCarree(),df_trim['lon'].values,df_trim['lat'].values)\n",
    "point_locs_slp = proj.transform_points(ccrs.PlateCarree(),slpdf['lon'].values,slpdf['lat'].values)\n",
    "\n",
    "xp,yp,null = point_locs_slp.T\n",
    "    \n",
    "if successive_corrections:\n",
    "    ROIs = [500000,400000,300000,200000]\n",
    "    #first pass\n",
    "    slpgridx, slpgridy, slp = interpolate_to_grid(xp,yp,slpdf['pres'],\n",
    "                                              interp_type='cressman',\n",
    "                                              minimum_neighbors=1,hres=20000,search_radius=ROIs[0])\n",
    "    SLP = np.zeros((len(ROIs),len(slp),len(slp[0])))\n",
    "    SLP[0] = slp\n",
    "    grid = np.transpose([slpgridx.ravel(),slpgridy.ravel()])\n",
    "    stns = np.transpose([xp,yp])\n",
    "    for i in range(1,len(ROIs)):\n",
    "        #interpolate gridded slp to obs locations:\n",
    "        slp_bg = interpolate_to_points(grid,SLP[i-1].ravel(),stns,interp_type='cressman',search_radius=ROIs[i-1])\n",
    "        \n",
    "        #calculate next pass\n",
    "        slpgridx, slpgridy, slp = interpolate_to_grid(xp,yp,slpdf['pres']-slp_bg,interp_type='cressman',minimum_neighbors=1,hres=20000,search_radius=ROIs[i])\n",
    "        SLP[i] = np.nansum([slp,SLP[i-1]],axis=0)\n",
    "        slp = SLP[i]\n",
    "        \n",
    "else:\n",
    "    slpgridx, slpgridy, slp = interpolate_to_grid(xp,yp,slpdf['pres'],\n",
    "                                              interp_type='cressman',\n",
    "                                              minimum_neighbors=1,hres=20000,search_radius=search_radius)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting data\n",
    "\n",
    "Data is plotted and a map is produced for each hour requested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmarquis/miniconda3/envs/work/lib/python3.10/site-packages/cartopy/io/__init__.py:241: DownloadWarning: Downloading: https://naturalearth.s3.amazonaws.com/50m_physical/ne_50m_land.zip\n",
      "  warnings.warn(f'Downloading: {url}', DownloadWarning)\n",
      "/home/jmarquis/miniconda3/envs/work/lib/python3.10/site-packages/cartopy/io/__init__.py:241: DownloadWarning: Downloading: https://naturalearth.s3.amazonaws.com/50m_physical/ne_50m_ocean.zip\n",
      "  warnings.warn(f'Downloading: {url}', DownloadWarning)\n"
     ]
    }
   ],
   "source": [
    "point_density = 75000.\n",
    "\n",
    "df_plot = df_trim[reduce_point_density(point_locs,point_density)]\n",
    "    \n",
    "fig=plt.figure(figsize=(11,6.5),dpi=300)\n",
    "ax = fig.add_subplot(1,1,1,projection=proj)\n",
    "#img = plt.imread('../basemaps/natural_earth.tif')\n",
    "#img_extent = (-180,180,-90,90)\n",
    "#ax.imshow(img,origin='upper',extent=img_extent,transform=ccrs.PlateCarree())\n",
    "ax.add_feature(cfeature.NaturalEarthFeature('physical','land','50m',facecolor='oldlace'))\n",
    "ax.add_feature(cfeature.NaturalEarthFeature('physical','ocean','50m',facecolor='lightcyan'))\n",
    "ax.add_feature(cfeature.STATES)\n",
    "ax.add_feature(cfeature.COASTLINE)\n",
    "ax.set_extent((lon_min,lon_max,lat_min,lat_max))\n",
    "\n",
    "stationplot = StationPlot(ax,df_plot['lon'].values,df_plot['lat'].values,clip_on=True, transform=ccrs.PlateCarree(),fontsize=8)\n",
    "#stationplot.plot_text((2.1,0),df_plot['name'].values,fontsize=4,color='gray')\n",
    "stationplot.plot_parameter('NW',df_plot['temp']*(9.0/5.0)+32.0,color='darkred',fontsize=8)\n",
    "stationplot.plot_parameter('NE',df_plot['pres'],color='black',formatter=lambda v: format(10 * v, '.0f')[-3:],fontsize=8)\n",
    "stationplot.plot_parameter('SW',df_plot['dwpt']*(9.0/5.0)+32.0,color='darkgreen',fontsize=8)\n",
    "stationplot.plot_barb(np.array(df_plot['u'].values,dtype=float),np.array(df_plot['v'].values,dtype=float),linewidth=0.7,length=6,zorder=10)\n",
    "cs = plt.contour(slpgridx,slpgridy,slp,colors='k',levels=list(range(900,1034,4)),linewidths=1)\n",
    "plt.clabel(cs, inline=1, fontsize=8, fmt='%i')\n",
    "stationplot.plot_symbol('C',df['sky_cvr'].values,sky_cover)\n",
    "stationplot.plot_symbol('W',df['wx'].values,current_weather,fontsize=12)\n",
    "#plt.suptitle(dt_str)\n",
    "fig.tight_layout()\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
